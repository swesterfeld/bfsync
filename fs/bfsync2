#!/usr/bin/env python

# bfsync: Big File synchronization based on Git

# Copyright (C) 2011 Stefan Westerfeld
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import sys
import os
import subprocess
import hashlib
import pickle
import traceback
import time
import tempfile
import CfgParser
import HashCache
import StatusLine
import shutil
import argparse

from utils import mkdir_recursive
from TransferList import TransferList, TransferFile
from StatusLine import status_line
from HashCache import hash_cache
from stat import *

def find_bfsync_dir():
  old_cwd = os.getcwd()
  dir = old_cwd
  while True:
    try:
      test_dir = os.path.join (dir, ".bfsync")
      os.chdir (test_dir)
      os.chdir (old_cwd)
      return test_dir
    except:
      pass
    # try parent directory
    newdir = os.path.dirname (dir)
    if newdir == dir:
      # no more parent
      raise Exception ("can not find .bfsync directory")
    dir = newdir

def commit_msg_ok (filename):
  file = open (filename, "r")
  result = False
  for line in file:
    line = line.strip()
    if len (line):
      if line[0] == "#":
        pass
      else:
        result = True
  file.close()
  return result

def make_object_filename (hash):
  if len (hash) != 40:
    raise Exception ("bad hash %s (not len 40)" % hash)
  return hash[0:2] + "/" + hash[2:]

def validate_object (object_file, hash):
  try:
    os.stat (object_file)
    if hash_cache.compute_hash (object_file) == hash:
      return True
  except:
    pass
  return False

###################
FILE_REGULAR    = 1
FILE_SYMLINK    = 2
FILE_DIR        = 3
FILE_FIFO       = 4
FILE_SOCKET     = 5
FILE_BLOCK_DEV  = 6
FILE_CHAR_DEV   = 7
###################

def name2git_name (name):
  name = os.path.normpath (name)
  result = ""
  path = name.split ("/")
  for i in path[:-1]:
    result += "d_" + i + "/"
  result += "i_" + path[-1]
  return result

class GitFile:
  def __init__ (self):
    self.attrs = dict()
  def parse (self, filename):
    gfr = open (filename, "r")
    for line in gfr.readlines():
      l = line.strip().split (" ")
      self.attrs[l[0]] = l[2]
    gfr.close()
  def save (self, filename):
    gf = open (filename, "w")
    keys = sorted (self.attrs.keys())
    for k in keys:
      gf.write ("%s = %s\n" % (k, self.attrs[k]))
    gf.close()
  def get (self, key):
    return self.attrs[key]
  def set (self, key, value):
    self.attrs[key] = value

# python stat resolution is not nanosecond accurate, so we use a helper program
def get_times (file_list):
  (fd, stat_filename) = tempfile.mkstemp (prefix = "bfsync_git_stat_")
  stat_file = os.fdopen (fd, "w")
  for (filename, filetype) in file_list:
    stat_file.write (filename + "\0")
  stat_file.close();
  stat_p =  subprocess.Popen(["xargs", "-0", "-a", stat_filename, "bfsyncstat"], stdout = subprocess.PIPE)
  result = stat_p.communicate()[0]
  os.remove (stat_filename)
  stat_list = result.split ("\0")
  stat_dict = dict()
  i = 0
  while (i + 3) < len (stat_list):
    stat_dict[stat_list[i]] = (int (stat_list[i + 1]), int (stat_list[i + 2]))
    i += 3
  return stat_dict

def cmd_commit():
  parser = argparse.ArgumentParser (prog='bfsync2 commit')
  parser.add_argument ('-m', help='set commit message')
  parser.add_argument ('repo_path', help='path to the repository')
  commit_args = parser.parse_args (args)

  os.chdir (commit_args.repo_path)
  bfsync_dir = find_bfsync_dir()
  bfsync_info = CfgParser.CfgParser ((bfsync_dir + "/info"),
  [
  ],
  [
    "repo-path",
    "mount-point"
  ])

  repo_path = bfsync_info.get ("repo-path")
  if len (repo_path) != 1:
    raise Exception ("bad repo path")
  repo_path = repo_path[0]

  mount_point = bfsync_info.get ("mount-point")
  if len (mount_point) != 1:
    raise Exception ("bad mount point")
  mount_point = mount_point[0]

  # chdir to repo_path to allow unmount
  os.chdir (repo_path)
  if subprocess.call (["fusermount", "-u", mount_point]) != 0:
    raise Exception ("umount failed")

  os.chdir (os.path.join (repo_path, "new"))
  file_list = []
  hash_list = []
  if True:
    for dir, dirs, files in os.walk ("."):
      for d in dirs:
        dirname = os.path.normpath (os.path.join (dir, d))
        if (os.path.islink (dirname)):      # symlinks to directories should be treated as links (not dirs)
          file_list += [ (dirname, FILE_SYMLINK) ]
        else:
          file_list += [ (dirname, FILE_DIR) ]
      for file in files:
        filename = os.path.normpath (os.path.join (dir, file))
        stat = os.lstat (filename)
        if S_ISREG (stat.st_mode):
          file_list += [ (filename, FILE_REGULAR) ]
          hash_list += [ filename ]
        else:
          raise Exception ("file '%s' has unknown type - cannot commit" % filename)

  os.chdir (os.path.join (repo_path, "new"))
  hash_cache.hash_all (hash_list)
  status_line.cleanup()

  (fd,commit_msg_filename) = tempfile.mkstemp (prefix = "bfsync_commit_")
  f = os.fdopen (fd, "w")
  if commit_args.m:
    f.write (commit_args.m)
  f.write("\n")
  for (filename, filetype) in file_list:
    f.write ("# add ")
    if (filetype == FILE_SYMLINK):
      f.write ("symlink ")
    elif (filetype == FILE_DIR):
      f.write ("dir ")
    f.write ("%s\n" % filename)
  f.close()
  if not commit_args.m:
    os.system ("vim %s" % commit_msg_filename)
  if not commit_msg_ok (commit_msg_filename):
    os.remove (commit_msg_filename)
    raise Exception ("commit message is empty")

  time_dict = get_times (file_list)

  # create entries in git/files for newly added files
  status_line.set_op ("GIT-ADD")
  count = len (file_list)
  add_count = 0
  for (filename, filetype) in file_list:
    try:
      new_file = os.path.join (repo_path, "new", filename)
      stat = os.lstat (new_file)
      if filetype == FILE_REGULAR:
        hash = hash_cache.compute_hash (new_file)
        size = stat.st_size
      mode = stat.st_mode;
    except Exception, ex:
      raise

    git_file = os.path.join (repo_path, "git/files", name2git_name (filename))
    mkdir_recursive (os.path.dirname (git_file))

    gf_attrs = GitFile()
    gf_attrs.parse (git_file)
    rehash = False
    try:
      rehash = gf_attrs.get ("hash") == "new"
    except:
      pass
    if rehash and filetype == FILE_REGULAR:
      gf_attrs.set ("size", str (size))
      gf_attrs.set ("hash", hash)
      mtimes = time_dict[filename]
      gf_attrs.set ("mtime", mtimes[0])
      gf_attrs.set ("mtime_ns", mtimes[1])
      gf_attrs.save (git_file)
    add_count += 1
    status_line.update ("file %d/%d" % (add_count, count))

  status_line.cleanup()

  # commit changes to repo
  os.chdir (os.path.join (repo_path, "git"))
  if os.system ("git add -A") != 0:
    raise Exception ("git add -A failed")
  if os.system ("git commit -q -a -F %s" % commit_msg_filename) != 0:
    raise Exception ("git commit failed")
  os.remove (commit_msg_filename)

  # copy files into objects/ directory
  tl = TransferList()
  have_hash = dict()
  for (filename, filetype) in file_list:
    if filetype == FILE_REGULAR:
      new_file = os.path.join (repo_path, "new", filename)
      hash = hash_cache.compute_hash (new_file)
      object_file = os.path.join (repo_path, "objects", make_object_filename (hash))
      if not validate_object (object_file, hash) and not (hash in have_hash):
        mkdir_recursive (os.path.dirname (object_file))
        tl.add (TransferFile (new_file, object_file, os.path.getsize (new_file), 0444))
        # copy duplicate files only once:
        have_hash[hash] = True
  status_line.set_op ("COPY")
  tl.copy_files()

  # remove files from new/ directory
  for (filename, filetype) in file_list:
    if filetype != FILE_DIR:
      new_file = os.path.join (repo_path, "new", filename)
      os.remove (new_file)

  # remove dirs form new/ directory (sort by length, so delete subdirs first)
  sorted_list = sorted (file_list, key = lambda (name, t): -len (name))
  for (filename, filetype) in sorted_list:
    if filetype == FILE_DIR:
      new_dir = os.path.join (repo_path, "new", filename)
      os.rmdir (new_dir)
  return

command = None
command_func = None
arg_iter = sys.argv[1:].__iter__()
args = []

for arg in arg_iter:
  commands = [
    ( "commit",         cmd_commit, 1),
  ]
  parse_ok = False
  if command == None:
    for c in commands:
      if c[0] == arg:
        command_func = c[1]
        command_args = c[2]
        command = c[0]
        parse_ok = True
  else:
    if command_args > 0:
      args += [ arg ]
      parse_ok = True
  if not parse_ok:
    sys.stderr.write ("can't parse command line args...\n")
    sys.exit (1)

if command_func != None:
  try:
    command_func()
  except Exception, ex:
    print "\n\n"
    print "=================================================="
    traceback.print_exc()
    print "=================================================="
    print "\n\n"
    hash_cache.save()
    sys.stderr.write ("bfsync2: %s\n" % ex)
    sys.exit (1)
  hash_cache.save()
else:
  print "usage: bfsync <command> [ args... ]"
