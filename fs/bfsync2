#!/usr/bin/env python

# bfsync: Big File synchronization based on Git

# Copyright (C) 2011 Stefan Westerfeld
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import sys
import os
import subprocess
import hashlib
import pickle
import traceback
import time
import tempfile
import CfgParser
import HashCache
import StatusLine
import shutil
import argparse

from utils import mkdir_recursive
from TransferList import TransferList, TransferFile
from StatusLine import status_line
from HashCache import hash_cache
from stat import *

def find_bfsync_dir():
  old_cwd = os.getcwd()
  dir = old_cwd
  while True:
    try:
      test_dir = os.path.join (dir, ".bfsync")
      os.chdir (test_dir)
      os.chdir (old_cwd)
      return test_dir
    except:
      pass
    # try parent directory
    newdir = os.path.dirname (dir)
    if newdir == dir:
      # no more parent
      raise Exception ("can not find .bfsync directory")
    dir = newdir

def commit_msg_ok (filename):
  file = open (filename, "r")
  result = False
  for line in file:
    line = line.strip()
    if len (line):
      if line[0] == "#":
        pass
      else:
        result = True
  file.close()
  return result

def make_object_filename (hash):
  if len (hash) != 40:
    raise Exception ("bad hash %s (not len 40)" % hash)
  return hash[0:2] + "/" + hash[2:]

def validate_object (object_file, hash):
  try:
    os.stat (object_file)
    if hash_cache.compute_hash (object_file) == hash:
      return True
  except:
    pass
  return False

###################
FILE_REGULAR    = 1
FILE_SYMLINK    = 2
FILE_DIR        = 3
FILE_FIFO       = 4
FILE_SOCKET     = 5
FILE_BLOCK_DEV  = 6
FILE_CHAR_DEV   = 7
###################

def name2git_name (name):
  name = os.path.normpath (name)
  result = ""
  path = name.split ("/")
  for i in path[:-1]:
    result += "d_" + i + "/"
  result += "i_" + path[-1]
  return result

class GitFile:
  def __init__ (self):
    self.attrs = dict()
  def parse (self, filename):
    gfr = open (filename, "r")
    for line in gfr.readlines():
      l = line.strip().split (" ")
      self.attrs[l[0]] = l[2]
    gfr.close()
  def save (self, filename):
    gf = open (filename, "w")
    keys = sorted (self.attrs.keys())
    for k in keys:
      gf.write ("%s = %s\n" % (k, self.attrs[k]))
    gf.close()
  def get (self, key):
    return self.attrs[key]
  def set (self, key, value):
    self.attrs[key] = value

# python stat resolution is not nanosecond accurate, so we use a helper program
def get_times (file_list):
  (fd, stat_filename) = tempfile.mkstemp (prefix = "bfsync_git_stat_")
  stat_file = os.fdopen (fd, "w")
  for (filename, filetype) in file_list:
    stat_file.write (filename + "\0")
  stat_file.close();
  stat_p =  subprocess.Popen(["xargs", "-0", "-a", stat_filename, "bfsyncstat"], stdout = subprocess.PIPE)
  result = stat_p.communicate()[0]
  os.remove (stat_filename)
  stat_list = result.split ("\0")
  stat_dict = dict()
  i = 0
  while (i + 3) < len (stat_list):
    stat_dict[stat_list[i]] = (int (stat_list[i + 1]), int (stat_list[i + 2]))
    i += 3
  return stat_dict

def parse_config (filename):
  bfsync_info = CfgParser.CfgParser (filename,
  [
  ],
  [
    "repo-type",
    "repo-path",
    "mount-point"
  ])
  return bfsync_info

def cmd_commit():
  parser = argparse.ArgumentParser (prog='bfsync2 commit')
  parser.add_argument ('-m', help='set commit message')
  parser.add_argument ('repo_path', help='path to the repository')
  commit_args = parser.parse_args (args)

  os.chdir (commit_args.repo_path)
  bfsync_dir = find_bfsync_dir()

  bfsync_info = parse_config (bfsync_dir + "/info")

  repo_path = bfsync_info.get ("repo-path")
  if len (repo_path) != 1:
    raise Exception ("bad repo path")
  repo_path = repo_path[0]

  mount_point = bfsync_info.get ("mount-point")
  if len (mount_point) != 1:
    raise Exception ("bad mount point")
  mount_point = mount_point[0]

  # chdir to repo_path to allow unmount
  os.chdir (repo_path)
  if subprocess.call (["fusermount", "-u", mount_point]) != 0:
    raise Exception ("umount failed")

  os.chdir (os.path.join (repo_path, "new"))
  file_list = []
  hash_list = []
  if True:
    for dir, dirs, files in os.walk ("."):
      for d in dirs:
        dirname = os.path.normpath (os.path.join (dir, d))
        if (os.path.islink (dirname)):      # symlinks to directories should be treated as links (not dirs)
          file_list += [ (dirname, FILE_SYMLINK) ]
        else:
          file_list += [ (dirname, FILE_DIR) ]
      for file in files:
        filename = os.path.normpath (os.path.join (dir, file))
        stat = os.lstat (filename)
        if S_ISREG (stat.st_mode):
          file_list += [ (filename, FILE_REGULAR) ]
          hash_list += [ filename ]
        else:
          raise Exception ("file '%s' has unknown type - cannot commit" % filename)

  os.chdir (os.path.join (repo_path, "new"))
  hash_cache.hash_all (hash_list)
  status_line.cleanup()

  (fd,commit_msg_filename) = tempfile.mkstemp (prefix = "bfsync_commit_")
  f = os.fdopen (fd, "w")
  if commit_args.m:
    f.write (commit_args.m)
  f.write("\n")
  for (filename, filetype) in file_list:
    f.write ("# add ")
    if (filetype == FILE_SYMLINK):
      f.write ("symlink ")
    elif (filetype == FILE_DIR):
      f.write ("dir ")
    f.write ("%s\n" % filename)
  f.close()
  if not commit_args.m:
    os.system ("vim %s" % commit_msg_filename)
  if not commit_msg_ok (commit_msg_filename):
    os.remove (commit_msg_filename)
    raise Exception ("commit message is empty")

  time_dict = get_times (file_list)

  # create entries in git/files for newly added files
  status_line.set_op ("GIT-ADD")
  count = len (file_list)
  add_count = 0
  for (filename, filetype) in file_list:
    try:
      new_file = os.path.join (repo_path, "new", filename)
      stat = os.lstat (new_file)
      if filetype == FILE_REGULAR:
        hash = hash_cache.compute_hash (new_file)
        size = stat.st_size
      mode = stat.st_mode;
    except Exception, ex:
      raise

    git_file = os.path.join (repo_path, "git/files", name2git_name (filename))
    mkdir_recursive (os.path.dirname (git_file))

    gf_attrs = GitFile()
    gf_attrs.parse (git_file)
    rehash = False
    try:
      rehash = gf_attrs.get ("hash") == "new"
    except:
      pass
    if rehash and filetype == FILE_REGULAR:
      gf_attrs.set ("size", str (size))
      gf_attrs.set ("hash", hash)
      mtimes = time_dict[filename]
      gf_attrs.set ("mtime", mtimes[0])
      gf_attrs.set ("mtime_ns", mtimes[1])
      gf_attrs.save (git_file)
    add_count += 1
    status_line.update ("file %d/%d" % (add_count, count))

  status_line.cleanup()

  # commit changes to repo
  os.chdir (os.path.join (repo_path, "git"))
  if os.system ("git add -A") != 0:
    raise Exception ("git add -A failed")
  if os.system ("git commit -q -a -F %s" % commit_msg_filename) != 0:
    raise Exception ("git commit failed")
  os.remove (commit_msg_filename)

  # copy files into objects/ directory
  tl = TransferList()
  have_hash = dict()
  for (filename, filetype) in file_list:
    if filetype == FILE_REGULAR:
      new_file = os.path.join (repo_path, "new", filename)
      hash = hash_cache.compute_hash (new_file)
      object_file = os.path.join (repo_path, "objects", make_object_filename (hash))
      if not validate_object (object_file, hash) and not (hash in have_hash):
        mkdir_recursive (os.path.dirname (object_file))
        tl.add (TransferFile (new_file, object_file, os.path.getsize (new_file), 0444))
        # copy duplicate files only once:
        have_hash[hash] = True
  status_line.set_op ("COPY")
  tl.copy_files()

  # remove files from new/ directory
  for (filename, filetype) in file_list:
    if filetype != FILE_DIR:
      new_file = os.path.join (repo_path, "new", filename)
      os.remove (new_file)

  # remove dirs form new/ directory (sort by length, so delete subdirs first)
  sorted_list = sorted (file_list, key = lambda (name, t): -len (name))
  for (filename, filetype) in sorted_list:
    if filetype == FILE_DIR:
      new_dir = os.path.join (repo_path, "new", filename)
      os.rmdir (new_dir)

  # auto-remount
  if os.system ("bfsyncfs %s %s" % (repo_path, mount_point)) != 0:
    raise Exception ("auto-remount failed")
  return

def strip_git_suffix (s):
  if s[-4:] == ".git":
    return s[:-4]
  else:
    return s

def guess_dir_name (url):
  dir_name = ""
  for ch in reversed (url):
    if (ch == ":") or (ch == "/"):
      return strip_git_suffix (dir_name)
    dir_name = ch + dir_name
  return strip_git_suffix (dir_name)

def cmd_clone():
  parser = argparse.ArgumentParser (prog='bfsync2 clone')
  parser.add_argument ('repo', help='path/url of the repository')
  clone_args = parser.parse_args (args)
  destdir = guess_dir_name (clone_args.repo)
  if os.path.exists (destdir):
    raise Exception ("fatal: destination path '" + destdir + "' already exists")
  if subprocess.call (["mkdir", "-p", destdir + "/new",
                                      destdir + "/objects",
                                      destdir + "/git",
                                      destdir + "/.bfsync"]) != 0:
    raise Exception ("creating directories failed")
  if os.system ("git clone %s %s/git" % (clone_args.repo, destdir)) != 0:
    try:
      os.rmdir (destdir)
    except:
      pass
    raise Exception ("git clone failed")
  infoname = destdir + "/.bfsync/info"
  try:
    f = open (infoname, "w")
    f.write ("repo-type store;\n")
    f.close()
  except:
    raise Exception ("unable to write initial repo info file %s" % infoname)
  if subprocess.call (["mkdir", "-p", destdir + "/git/files"]) != 0:
    raise Exception ("creating files directory failed")
  return

def remote_get (url):
  repo_dir = find_repo_dir()
  status_line.update ("checking local files...")
  missing = check (repo_dir, False)
  #failed = process_excludes (failed) # TODO
  if len (missing) == 0:
    status_line.cleanup()
    print "All files up to date; nothing to do."
    return

def local_get (src):
  repo_dir = find_repo_dir()
  object_list = check (repo_dir, False)
  hash_needed = dict()
  tl = TransferList()
  for hash in object_list:
    if not hash_needed.has_key (hash):
      hash_needed[hash] = True
      obj_name = os.path.join ("objects", make_object_filename (hash))
      src_name = os.path.join (src, obj_name)
      dest_name = os.path.join (repo_dir, obj_name)
      if os.path.exists (src_name) and hash_cache.compute_hash (src_name) == hash:
        tl.add (TransferFile (src_name, dest_name, os.path.getsize (src_name), 0400))
  tl.copy_files()
  return

def cmd_get():
  status_line.set_op ("GET")
  #if len (args) == 0:
    #my_args = bfsync_config.get ("default/get")
  #else:
    #my_args = args
  for src in args:
    if len (src.split (":")) > 1:
      remote_get (src)
    else:
      local_get (src)
  return

def git_name2file_name (repo_dir, v):
  prefix = os.path.join (repo_dir, "git", "files")
  if v[0:len(prefix)] == prefix:
    v = v[len(prefix):]
  result = ""
  for p in v.split ("/"):
    if p[0:2] == "i_" or p[0:2] == "d_":
      p = p[2:]
    if result != "":
      result += "/"
    result += p
  return result

def check (repo_dir, show_progress):
  check_list = []
  missing_list = []
  for dir, dirs, files in os.walk (os.path.join (repo_dir, "git")):
    if '.git' in dirs:
      dirs.remove ('.git')
    for file in files:
      check_list += [ os.path.join (dir, file) ]
  for v in check_list:
    if (show_progress):
      sys.stdout.write ("checking %s... " % git_name2file_name (repo_dir, v))
      sys.stdout.flush()
    gf_attrs = GitFile()
    gf_attrs.parse (v)
    try:
      hash = gf_attrs.get ("hash")
    except:
      hash = "none"
    if hash == "new":
      state = "CHANGED"
    elif hash == "none":
      state = "OK"
    else:
      object_name = os.path.join (repo_dir, "objects", make_object_filename (hash))
      if not os.path.exists (object_name):
        missing_list += [ hash ]
        state = "MISSING"
      else:
        if hash_cache.compute_hash (object_name) == hash:
          if show_progress:
            state = "OK"
        else:
          missing_list += [ hash ]
          state = "MISSING"
    if show_progress:
      print "%s." % state
  return missing_list

def cmd_check():
  repo_dir = find_repo_dir()
  check (repo_dir, True)
  return

def cmd_push():
  repo_dir = os.path.join (find_repo_dir(), "git")
  try:
    os.chdir (repo_dir)
    if os.system ("git push origin master") != 0:
      raise Exception ("git push failed")
  except:
    raise Exception ("cannot chdir to directory %s" % repo_dir)
  return

def find_repo_dir():
  dir = os.getcwd()
  while True:
    file_ok = False
    try:
      cfg_file = os.path.join (dir, ".bfsync/info")
      f = open (cfg_file, "r")
      f.close()
      file_ok = True
    except:
      pass
    if file_ok:
      cfg = parse_config (cfg_file)
      repo_type_list = cfg.get ("repo-type")
      if len (repo_type_list) != 1:
        raise Exception ("bad repo-type list (should have exactly 1 entry)")
      if repo_type_list[0] == "store":
        pass # dir ok
      elif repo_type_list[0] == "mount":
        dir = cfg.get ("repo-path")
        if len (dir) == 1:
          dir = dir[0]
        else:
          raise Exception ("bad repo-path list (should have exactly 1 entry)")
      else:
        raise Exception ("unknown repo-type '%s' in find_repo_dir", cfg.get ("repo-type"))
      return dir
    # try parent directory
    newdir = os.path.dirname (dir)
    if newdir == dir:
      # no more parent
      raise Exception ("error: can not find .bfsync directory")
    dir = newdir

def cmd_pull():
  repo_dir = find_repo_dir() + "/git"
  try:
    os.chdir (repo_dir)
    if os.system ("git pull") != 0:
      raise Exception ("git pull failed")
  except:
    raise Exception ("cannot chdir to directory %s" % repo_dir)
  return

command = None
command_func = None
arg_iter = sys.argv[1:].__iter__()
args = []

for arg in arg_iter:
  commands = [
    ( "check",          cmd_check, 0),
    ( "clone",          cmd_clone, 1),
    ( "commit",         cmd_commit, 1),
    ( "get",            cmd_get, 1),
    ( "pull",           cmd_pull, 0),
    ( "push",           cmd_push, 0),
  ]
  parse_ok = False
  if command == None:
    for c in commands:
      if c[0] == arg:
        command_func = c[1]
        command_args = c[2]
        command = c[0]
        parse_ok = True
  else:
    if command_args > 0:
      args += [ arg ]
      parse_ok = True
  if not parse_ok:
    sys.stderr.write ("can't parse command line args...\n")
    sys.exit (1)

if command_func != None:
  try:
    command_func()
  except Exception, ex:
    print "\n\n"
    print "=================================================="
    traceback.print_exc()
    print "=================================================="
    print "\n\n"
    hash_cache.save()
    sys.stderr.write ("bfsync2: %s\n" % ex)
    sys.exit (1)
  hash_cache.save()
else:
  print "usage: bfsync <command> [ args... ]"
