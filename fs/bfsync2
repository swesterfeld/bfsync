#!/usr/bin/env python

# bfsync: Big File synchronization based on Git

# Copyright (C) 2011 Stefan Westerfeld
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import sys
import os
import subprocess
import hashlib
import pickle
import traceback
import time
import tempfile
import CfgParser
import HashCache
import StatusLine
import shutil
import argparse

from utils import mkdir_recursive
from TransferList import TransferList, TransferFile
from StatusLine import status_line
from HashCache import hash_cache
from stat import *

def find_bfsync_dir():
  old_cwd = os.getcwd()
  dir = old_cwd
  while True:
    try:
      test_dir = os.path.join (dir, ".bfsync")
      os.chdir (test_dir)
      os.chdir (old_cwd)
      return test_dir
    except:
      pass
    # try parent directory
    newdir = os.path.dirname (dir)
    if newdir == dir:
      # no more parent
      raise Exception ("can not find .bfsync directory")
    dir = newdir

def commit_msg_ok (filename):
  file = open (filename, "r")
  result = False
  for line in file:
    line = line.strip()
    if len (line):
      if line[0] == "#":
        pass
      else:
        result = True
  file.close()
  return result

def make_object_filename (hash):
  if len (hash) != 40:
    raise Exception ("bad hash %s (not len 40)" % hash)
  return hash[0:2] + "/" + hash[2:]

def validate_object (object_file, hash):
  try:
    os.stat (object_file)
    if hash_cache.compute_hash (object_file) == hash:
      return True
  except:
    pass
  return False

###################
FILE_REGULAR    = 1
FILE_SYMLINK    = 2
FILE_DIR        = 3
FILE_FIFO       = 4
FILE_SOCKET     = 5
FILE_BLOCK_DEV  = 6
FILE_CHAR_DEV   = 7
###################

def name2git_name (name):
  name = os.path.normpath (name)
  result = ""
  path = name.split ("/")
  for i in path[:-1]:
    result += "d_" + i + "/"
  result += "i_" + path[-1]
  return result

# python stat resolution is not nanosecond accurate, so we use a helper program
def get_times (file_list):
  (fd, stat_filename) = tempfile.mkstemp (prefix = "bfsync_git_stat_")
  stat_file = os.fdopen (fd, "w")
  for (filename, filetype) in file_list:
    stat_file.write (filename + "\0")
  stat_file.close();
  stat_p =  subprocess.Popen(["xargs", "-0", "-a", stat_filename, "bfsyncstat"], stdout = subprocess.PIPE)
  result = stat_p.communicate()[0]
  stat_list = result.split ("\0")
  stat_dict = dict()
  i = 0
  while (i + 3) < len (stat_list):
    stat_dict[stat_list[i]] = (int (stat_list[i + 1]), int (stat_list[i + 2]))
    i += 3
  return stat_dict

def cmd_commit():
  parser = argparse.ArgumentParser (prog='bfsync2 commit')
  parser.add_argument ('-m', help='set commit message')
  parser.add_argument ('repo_path', help='path to the repository')
  commit_args = parser.parse_args (args)

  os.chdir (commit_args.repo_path)
  bfsync_dir = find_bfsync_dir()
  bfsync_info = CfgParser.CfgParser ((bfsync_dir + "/info"),
  [
  ],
  [
    "repo-path",
    "mount-point"
  ])

  repo_path = bfsync_info.get ("repo-path")
  if len (repo_path) != 1:
    raise Exception ("bad repo path")
  repo_path = repo_path[0]

  mount_point = bfsync_info.get ("mount-point")
  if len (mount_point) != 1:
    raise Exception ("bad mount point")
  mount_point = mount_point[0]

  # chdir to repo_path to allow unmount
  os.chdir (repo_path)
  if subprocess.call (["fusermount", "-u", mount_point]) != 0:
    raise Exception ("umount failed")

  os.chdir (os.path.join (repo_path, "new"))
  file_list = []
  hash_list = []
  for dir, dirs, files in os.walk ("."):
    for d in dirs:
      dirname = os.path.normpath (os.path.join (dir, d))
      if (os.path.islink (dirname)):      # symlinks to directories should be treated as links (not dirs)
        file_list += [ (dirname, FILE_SYMLINK) ]
      else:
        file_list += [ (dirname, FILE_DIR) ]
    for file in files:
      filename = os.path.normpath (os.path.join (dir, file))
      stat = os.lstat (filename)
      if S_ISREG (stat.st_mode):
        file_list += [ (filename, FILE_REGULAR) ]
        hash_list += [ filename ]
      elif S_ISLNK (stat.st_mode):
        file_list += [ (filename, FILE_SYMLINK) ]
      elif S_ISFIFO (stat.st_mode):
        file_list += [ (filename, FILE_FIFO) ]
      elif S_ISSOCK (stat.st_mode):
        file_list += [ (filename, FILE_SOCKET) ]
      elif S_ISBLK (stat.st_mode):
        file_list += [ (filename, FILE_BLOCK_DEV) ]
      elif S_ISCHR (stat.st_mode):
        file_list += [ (filename, FILE_CHAR_DEV) ]
      else:
        raise Exception ("file '%s' has unknown type - cannot commit" % filename)

  os.chdir (os.path.join (repo_path, "del"))
  del_list = []
  for dir, dirs, files in os.walk ("."):
    for file in files:
      filename = os.path.normpath (os.path.join (dir, file))
      stat = os.lstat (filename)
      if S_ISREG (stat.st_mode):
        del_list += [ filename ]
      else:
        raise Exception ("deleted file '%s' has unknown type - cannot commit" % filename)

  os.chdir (os.path.join (repo_path, "new"))
  hash_cache.hash_all (hash_list)
  status_line.cleanup()

  (fd,commit_msg_filename) = tempfile.mkstemp (prefix = "bfsync_commit_")
  f = os.fdopen (fd, "w")
  if commit_args.m:
    f.write (commit_args.m)
  f.write("\n")
  for (filename, filetype) in file_list:
    f.write ("# add ")
    if (filetype == FILE_SYMLINK):
      f.write ("symlink ")
    elif (filetype == FILE_DIR):
      f.write ("dir ")
    f.write ("%s\n" % filename)
  for filename in del_list:
    f.write ("# del ")
    f.write ("%s\n" % filename)
  f.close()
  if not commit_args.m:
    os.system ("vim %s" % commit_msg_filename)
  if not commit_msg_ok (commit_msg_filename):
    os.remove (commit_msg_filename)
    raise Exception ("commit message is empty")

  # get times for new files
  time_dict = get_times (file_list)

  # create entries in git/files for newly added files
  status_line.set_op ("GIT-ADD")
  count = len (file_list)
  add_count = 0
  for (filename, filetype) in file_list:
    try:
      new_file = os.path.join (repo_path, "new", filename)
      stat = os.lstat (new_file)
      if filetype == FILE_REGULAR:
        hash = hash_cache.compute_hash (new_file)
        size = stat.st_size
      elif filetype == FILE_SYMLINK:
        link = os.readlink (new_file)
      mode = stat.st_mode;
      times = time_dict[filename]
      mtime = times[0]
      mtime_ns = times[1]
    except Exception, ex:
      raise

    git_file = os.path.join (repo_path, "git/files", name2git_name (filename))
    mkdir_recursive (os.path.dirname (git_file))
    try:
      gf = open (git_file, "w")
      if filetype == FILE_REGULAR:
        gf.write ("type = file\n")
        gf.write ("hash = %s\n" % hash)
        gf.write ("size = %d\n" % size)
      elif filetype == FILE_SYMLINK:
        gf.write ("type = symlink\n")
        gf.write ("link = %s\n" % link)
      elif filetype == FILE_DIR:
        gf.write ("type = dir\n")
      elif filetype == FILE_FIFO:
        gf.write ("type = fifo\n")
      elif filetype == FILE_SOCKET:
        gf.write ("type = socket\n")
      elif filetype == FILE_BLOCK_DEV:
        gf.write ("type = blockdev\n")
      elif filetype == FILE_CHAR_DEV:
        gf.write ("type = chardev\n")
      if filetype == FILE_BLOCK_DEV or filetype == FILE_CHAR_DEV:
        # save major,minor pair for devices
        gf.write ("major = %d\n" % os.major (stat.st_rdev))
        gf.write ("minor = %d\n" % os.minor (stat.st_rdev))
      gf.write ("uid = %d\n" % stat.st_uid)
      gf.write ("gid = %d\n" % stat.st_gid)
      gf.write ("mode = %o\n" % mode)
      gf.write ("mtime = %d\n" % mtime)
      gf.write ("mtime_ns = %d\n" % mtime_ns)
      gf.close()
    except Exception, ex:
      raise
    add_count += 1
    status_line.update ("file %d/%d" % (add_count, count))

  # remove entries in git/files for deleted files/dirs
  # status_line.set_op ("GIT-RM")
  # count = len (del_list)
  # del_count = 0
  # for filename in del_list:
    # git_file = os.path.join (repo_path, "git/files", filename)
    # os.remove (git_file)
    # del_count += 1
    # status_line.update ("file %d/%d" % (del_count, count))

  status_line.cleanup()

  # commit changes to repo
  os.chdir (os.path.join (repo_path, "git"))
  if os.system ("git add -A") != 0:
    raise Exception ("git add -A failed")
  if os.system ("git commit -q -a -F %s" % commit_msg_filename) != 0:
    raise Exception ("git commit failed")
  os.remove (commit_msg_filename)

  # copy files into objects/ directory
  tl = TransferList()
  have_hash = dict()
  for (filename, filetype) in file_list:
    if filetype == FILE_REGULAR:
      new_file = os.path.join (repo_path, "new", filename)
      hash = hash_cache.compute_hash (new_file)
      object_file = os.path.join (repo_path, "objects", make_object_filename (hash))
      if not validate_object (object_file, hash) and not (hash in have_hash):
        mkdir_recursive (os.path.dirname (object_file))
        tl.add (TransferFile (new_file, object_file, os.path.getsize (new_file), 0444))
        # copy duplicate files only once:
        have_hash[hash] = True
  status_line.set_op ("COPY")
  tl.copy_files()

  # remove files from new/ directory
  for (filename, filetype) in file_list:
    if filetype != FILE_DIR:
      new_file = os.path.join (repo_path, "new", filename)
      os.remove (new_file)

  # remove dirs form new/ directory (sort by length, so delete subdirs first)
  sorted_list = sorted (file_list, key = lambda (name, t): -len (name))
  for (filename, filetype) in sorted_list:
    if filetype == FILE_DIR:
      new_dir = os.path.join (repo_path, "new", filename)
      os.rmdir (new_dir)

  # remove files from del/ directory
  for filename in del_list:
    del_file = os.path.join (repo_path, "del", filename)
    os.remove (del_file)
  return

command = None
command_func = None
arg_iter = sys.argv[1:].__iter__()
args = []

for arg in arg_iter:
  commands = [
    ( "commit",         cmd_commit, 1),
  ]
  parse_ok = False
  if command == None:
    for c in commands:
      if c[0] == arg:
        command_func = c[1]
        command_args = c[2]
        command = c[0]
        parse_ok = True
  else:
    if command_args > 0:
      args += [ arg ]
      parse_ok = True
  if not parse_ok:
    sys.stderr.write ("can't parse command line args...\n")
    sys.exit (1)

if command_func != None:
  try:
    command_func()
  except Exception, ex:
    print "\n\n"
    print "=================================================="
    traceback.print_exc()
    print "=================================================="
    print "\n\n"
    hash_cache.save()
    sys.stderr.write ("bfsync2: %s\n" % ex)
    sys.exit (1)
  hash_cache.save()
else:
  print "usage: bfsync <command> [ args... ]"
