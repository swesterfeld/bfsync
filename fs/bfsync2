#!/usr/bin/env python

# bfsync: Big File synchronization based on Git

# Copyright (C) 2011 Stefan Westerfeld
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import sys
import os
import subprocess
import hashlib
import cPickle
import traceback
import time
import tempfile
import CfgParser
import HashCache
import StatusLine
import shutil
import argparse
import sqlite3
import shutil
import datetime

from utils import *
from dbutils import *
from diffutils import diff
from applyutils import apply
from commitutils import commit
from remoteutils import *
from TransferList import TransferList, TransferFile
from StatusLine import status_line
from HashCache import hash_cache
from ServerConn import ServerConn
from RemoteRepo import RemoteRepo
from stat import *
from transferutils import get, get_remote_objects, push, pull

def find_bfsync_dir():
  old_cwd = os.getcwd()
  dir = old_cwd
  while True:
    try:
      test_dir = os.path.join (dir, ".bfsync")
      os.chdir (test_dir)
      os.chdir (old_cwd)
      return test_dir
    except:
      pass
    # try parent directory
    newdir = os.path.dirname (dir)
    if newdir == dir:
      # no more parent
      raise Exception ("can not find .bfsync directory")
    dir = newdir

def commit_msg_ok (filename):
  file = open (filename, "r")
  result = False
  for line in file:
    line = line.strip()
    if len (line):
      if line[0] == "#":
        pass
      else:
        result = True
  file.close()
  return result

def cmd_commit():
  parser = argparse.ArgumentParser (prog='bfsync2 commit')
  parser.add_argument ('-m', help='set commit message')
  commit_args = parser.parse_args (args)

  repo = cd_repo_connect_db()
  commit (repo)

def cmd_debug_load_all_inodes():
  bfsync_dir = find_bfsync_dir()

  bfsync_info = parse_config (bfsync_dir + "/info")

  repo_path = bfsync_info.get ("repo-path")
  if len (repo_path) != 1:
    raise Exception ("bad repo path")
  repo_path = repo_path[0]

  os.chdir (repo_path)
  server_conn = ServerConn (repo_path)
  print server_conn.process_call (["load-all-inodes"])[0]

def cmd_debug_perf_getattr():
  bfsync_dir = find_bfsync_dir()

  bfsync_info = parse_config (bfsync_dir + "/info")

  repo_path = bfsync_info.get ("repo-path")
  if len (repo_path) != 1:
    raise Exception ("bad repo path")
  repo_path = repo_path[0]

  os.chdir (repo_path)
  server_conn = ServerConn (repo_path)
  print server_conn.process_call (["perf-getattr", args[0], args[1]])[0]

def cmd_debug_clear_cache():
  bfsync_dir = find_bfsync_dir()

  bfsync_info = parse_config (bfsync_dir + "/info")

  repo_path = bfsync_info.get ("repo-path")
  if len (repo_path) != 1:
    raise Exception ("bad repo path")
  repo_path = repo_path[0]

  os.chdir (repo_path)
  server_conn = ServerConn (repo_path)
  server_conn.get_lock()
  server_conn.clear_cache()

def cmd_debug_integrity():
  repo = cd_repo_connect_db()
  conn = repo.conn
  repo_path = repo.path

  c = conn.cursor()
  c.execute ('''SELECT vmin, vmax,id FROM inodes''')
  fail = False
  inode_d = dict()
  conflicts = []
  for row in c:
    vmin = int (row[0])
    vmax = int (row[1])
    version = vmin
    while version <= vmax:
      s = "%d|%s" % (version, row[2])
      if inode_d.has_key (s):
        conflicts += [ (version, row[2]) ]
      inode_d[s] = 1
      version += 1

  for conflict in conflicts:
    version = conflict[0]
    id = conflict[1]
    print "error: version %d available more than once for inode %s, name %s" % (
           version, id, printable_name (c, id, version))
    fail = True

  c.execute ('''SELECT vmin, vmax, dir_id, name FROM links''')
  link_d = dict()
  conflicts = []
  for row in c:
    vmin = int (row[0])
    vmax = int (row[1])
    version = vmin
    while version <= vmax:
      s = "%d|%s|%s" % (version, row[2], row[3])
      if link_d.has_key (s):
        conflicts += [ (version, row[2], row[3]) ]
      link_d[s] = 1
      version += 1

  for conflict in conflicts:
    version = conflict[0]
    id = conflict[1]
    name = conflict[2]
    print "error: version %d available more than once for link %s->%s, name %s" % (
          version, id, name, os.path.join (printable_name (c, id, version), name))
    fail = True

  c.close()
  if fail:
    sys.exit (1)
  print "ok"
  return

def cmd_log():
  repo = cd_repo_connect_db()
  conn = repo.conn
  repo_path = repo.path

  c = conn.cursor()
  c.execute ('''SELECT * FROM history WHERE hash != '' ORDER BY version''')
  for row in c:
    version = row[0]
    hash    = row[1]
    author  = row[2]
    commit  = row[3]

    if commit != "":
      print "%4d   hash '%s', author '%s', msg '%s'" % (version, hash, author, commit)
  return

def cmd_status():
  repo = cd_repo_connect_db()
  conn = repo.conn
  repo_path = repo.path

  c = conn.cursor()

  VERSION = 1
  c.execute ('''SELECT version FROM history''')
  for row in c:
    VERSION = max (row[0], VERSION)
  c.execute ('''SELECT id FROM inodes WHERE vmin=%d AND vmax=%d''' % (VERSION, VERSION))
  inode_ids = []
  for row in c:
    inode_ids += [ row[0] ]
  c.execute ('''SELECT dir_id, name, inode_id FROM links WHERE vmin=%d AND vmax=%d''' % (VERSION, VERSION))
  link_ids = []
  for row in c:
    link_ids += [ row[0:3] ]
  print "%d inodes modified:" % len (inode_ids)
  print
  for id in inode_ids:
    print " - %s, name %s" % (id, printable_name (c, id, VERSION))
  print
  print "%d links modified:" % len (link_ids)
  print
  for lid in link_ids:
    print " - %s->%s, name %s" % (lid[0], lid[2], os.path.join (printable_name (c, lid[0], VERSION), lid[1]))

def cmd_revert():
  repo = cd_repo_connect_db()
  conn = repo.conn
  repo_path = repo.path

  c = conn.cursor()

  # lock repo to allow modifications
  server_conn = ServerConn (repo_path)
  server_conn.get_lock()

  if len (args) == 0:
    VERSION = 1
    c.execute ('''SELECT version FROM history''')
    for row in c:
      VERSION = max (row[0], VERSION)
    VERSION -= 1
  else:
    VERSION = int (args[0])
  print "reverting to version %d..." % VERSION
  c.execute ('''SELECT vmin, vmax, id FROM inodes WHERE vmax >= ?''', (VERSION, ))
  del_inode_list = []
  for row in c:
    vmin = row[0]
    vmax = row[1]
    id = row[2]
    if (vmin > VERSION):
      del_inode_list += [ (vmin, id) ]
  for vmin, id in del_inode_list:
    c.execute ('''DELETE FROM inodes WHERE vmin=? AND id=?''', (vmin, id))
  c.execute ('''SELECT vmin, vmax, dir_id, inode_id FROM links WHERE vmax >= ?''', (VERSION, ))
  del_link_list = []
  for row in c:
    vmin = row[0]
    vmax = row[1]
    dir_id = row[2]
    inode_id = row[3]
    if (vmin > VERSION):
      del_link_list += [ (vmin, dir_id, inode_id) ]
  for vmin, dir_id, inode_id in del_link_list:
    c.execute ('''DELETE FROM links WHERE vmin=? AND dir_id=? AND inode_id=?''', (vmin, dir_id, inode_id))

  c.execute ('''UPDATE inodes SET vmax=? WHERE vmax >= ?''', (VERSION + 1, VERSION))
  c.execute ('''UPDATE links SET vmax=? WHERE vmax >= ?''', (VERSION + 1, VERSION))
  c.execute ('''DELETE FROM history WHERE version > ?''', (VERSION, ))
  c.execute ('''INSERT INTO history VALUES (?,?,?,?,?)''', (VERSION + 1, "", "", "", 0))

  conn.commit()
  c.close()
  # we modified the db, so the fs needs to reload everything
  # in-memory cached items will not be correct
  server_conn.clear_cache()

def cmd_db_fingerprint():
  repo = cd_repo_connect_db()
  conn = repo.conn
  repo_path = repo.path
  c = conn.cursor()

  # lock repo to ensure changes are written before we do something
  server_conn = ServerConn (repo_path)
  server_conn.get_lock()

  c.execute ("SELECT * FROM inodes")
  inode_l = []
  for row in c:
    s = "i\0"
    for f in row:
      s += "%s\0" % f
    inode_l += [ s ]
  inode_l.sort()
  c.execute ("SELECT * FROM links")
  link_l = []
  for row in c:
    s = "l\0"
    for f in row:
      s += "%s\0" % f
    link_l += [ s ]
  link_l.sort()
  c.execute ("SELECT * FROM history")
  history_l = []
  for row in c:
    s = "h\0"
    for f in row:
      s += "%s\0" % f
    history_l += [ s ]
  history_l.sort()
  all_str = ""
  for r in link_l + inode_l + history_l:
    all_str += r + "\0"
  print hashlib.sha1 (all_str).hexdigest()

def cmd_remote():
  os.chdir (args[0])
  repo = cd_repo_connect_db()
  conn = repo.conn
  repo_path = repo.path
  c = conn.cursor()

  while True:
    command = sys.stdin.readline().strip()
    result = None
    if command == "history":
      result = cPickle.dumps (remote_history (repo))
    elif command == "ls":
      result = cPickle.dumps (remote_ls (repo))
    elif command == "send":
      remote_send()
    elif command == "receive":
      remote_receive()
    elif command == "update-history":
      dhlen = int (sys.stdin.readline())
      delta_history = cPickle.loads (sys.stdin.read (dhlen))

      result = remote_update_history (repo, delta_history)
    elif command == "need-objects":
      result = cPickle.dumps (remote_need_objects (repo))
    elif command == "":
      return
    else:
      raise Exception ("unknown command in cmd_remote(): '%s'" % command)
    if not result is None:
      sys.stdout.write ("%s\n%s" % (len (result), result))
      sys.stdout.flush()

def cmd_pull():
  repo = cd_repo_connect_db ()
  pull (repo, args)

def cmd_push():
  repo = cd_repo_connect_db()
  push (repo, args)

def cmd_get():
  repo = cd_repo_connect_db()

  get (repo, args)

def cmd_init():
  dir = args[0]
  try:
    os.mkdir (dir, 0700)
  except:
    raise Exception ("can't create directory %s for repository" % dir)
  bfsync_dir = os.path.join (dir, ".bfsync")
  os.mkdir (bfsync_dir)
  f = open (os.path.join (bfsync_dir, "info"), "w")
  f.write ("repo-type master;")
  f.close()
  f = open (os.path.join (bfsync_dir, "config"), "w")
  f.write ("sqlite-sync 0;")
  f.close()

  os.chdir (dir)

  # create objects directory
  os.mkdir ("objects", 0700)
  for i in range (0, 256):
    os.mkdir ("objects/%02x" % i, 0700)

  # create history table
  repo = cd_repo_connect_db()
  conn = repo.conn
  c = conn.cursor()
  c.execute ('''CREATE TABLE history
                 (
                   version integer,
                   hash    text,
                   author  text,
                   message text,
                   time    integer
                 )''')
  conn.commit()

  # create initial commit diff
  time_now = int (time.time())
  change_list = [
    "i+",
    "0" * 40,           # id (root inode)
    "%d" % os.getuid(), # uid
    "%d" % os.getgid(), # gid
    "%d" % 0755,        # mode
    "dir",              # type
    "", "", "0", "0", "0", "1",
    "%d" % time_now, "0", # ctime
    "%d" % time_now, "0"  # mtime
  ]

  f = open ("init-diff", "w")
  for s in change_list:
    f.write (s + "\0")
  f.close()
  os.system ("xz -9 init-diff")
  hash = move_file_to_objects (repo, "init-diff.xz")

  # create initial history entry
  c.execute ("""INSERT INTO history VALUES (1, ?, "no author", "initial commit", ?)""", (hash, time_now))
  conn.commit()

def guess_dir_name (url):
  dir_name = ""
  for ch in reversed (url):
    if (ch == ":") or (ch == "/"):
      return dir_name
    dir_name = ch + dir_name
  return url

def cmd_clone():
  url = args[0]
  if len (args) > 1:
    dir = args[1]
  else:
    dir = guess_dir_name (args[0])
  if os.path.exists (dir):
    print "fatal: destination path '" + dir + "' already exists"
    sys.exit (1)

  url_list = url.split (":")
  if len (url_list) == 1:
    # local repository => use absolute path
    url = os.path.abspath (url)

  print url, "=>", dir

  try:
    os.mkdir (dir, 0700)
  except:
    raise Exception ("can't create directory %s for repository" % dir)

  bfsync_dir = os.path.join (dir, ".bfsync")
  os.mkdir (bfsync_dir)

  # init .bfsync/info
  f = open (os.path.join (bfsync_dir, "info"), "w")
  f.write ("repo-type store;")
  f.close()

  # default config
  f = open (os.path.join (bfsync_dir, "config"), "w")
  f.write ("sqlite-sync 0;\n")
  f.write ("default {\n")
  f.write ("""  pull "%s";\n""" % url)
  f.write ("""  push "%s";\n""" % url)
  f.write ("}\n")
  f.close()

  os.chdir (dir)
  repo = cd_repo_connect_db()
  conn = repo.conn
  repo_path = repo.path
  c = conn.cursor()
  create_tables (c)
  init_tables (c)
  conn.commit()

  os.mkdir ("new", 0700)
  os.mkdir ("objects", 0700)
  for i in range (0, 256):
    os.mkdir ("new/%02x" % i, 0700)
    os.mkdir ("objects/%02x" % i, 0700)

  # mount for pull
  os.mkdir ("clone-mnt", 0700)
  if subprocess.call (["bfsyncfs", ".", "clone-mnt"]) != 0:
    raise Exception ("cannot mount repo")
  pull (repo, [ url ])
  if subprocess.call (["fusermount", "-u", "clone-mnt"]) != 0:
    raise Exception ("cannot umount repo")
  os.rmdir ("clone-mnt")
  # FIXME: ensure repo deletion on exception

command = None
command_func = None
arg_iter = sys.argv[1:].__iter__()
args = []

for arg in arg_iter:
  commands = [
    ( "commit",                 cmd_commit, 1),
    ( "log",                    cmd_log, 0),
    ( "pull",                   cmd_pull, 1),
    ( "push",                   cmd_push, 1),
    ( "get",                    cmd_get, 1),
    ( "status",                 cmd_status, 0),
    ( "revert",                 cmd_revert, 1),
    ( "init",                   cmd_init, 1),
    ( "clone",                  cmd_clone, 1),
    ( "db-fingerprint",         cmd_db_fingerprint, 0),
    ( "remote",                 cmd_remote, 1),
    ( "debug-load-all-inodes",  cmd_debug_load_all_inodes, 0),
    ( "debug-perf-getattr",     cmd_debug_perf_getattr, 1),
    ( "debug-clear-cache",      cmd_debug_clear_cache, 1),
    ( "debug-integrity",        cmd_debug_integrity, 0),
  ]
  parse_ok = False
  if command == None:
    for c in commands:
      if c[0] == arg:
        command_func = c[1]
        command_args = c[2]
        command = c[0]
        parse_ok = True
  else:
    if command_args > 0:
      args += [ arg ]
      parse_ok = True
  if not parse_ok:
    sys.stderr.write ("can't parse command line args...\n")
    sys.exit (1)

if command_func != None:
  try:
    if False: # profiling
      import cProfile

      cProfile.run ("command_func()", "/tmp/bfsync2-profile-%s" % command)
    else:
      command_func()
  except Exception, ex:
    print "\n\n"
    print "=================================================="
    traceback.print_exc()
    print "=================================================="
    print "\n\n"
    hash_cache.save()
    sys.stderr.write ("bfsync2: %s\n" % ex)
    sys.exit (1)
  hash_cache.save()
else:
  print "usage: bfsync <command> [ args... ]"
